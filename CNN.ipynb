{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Final Project material for the \"Deep Learning\" class I took  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset from https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "We only need CSV files that is preprocessed and labeled for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataroot = '/home/jovyan/ikt590'\n",
    "SEED=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_data\n",
    "X,y = load_data(dataroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import balance_data, normalize\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Classifier\n",
    "\n",
    "def ensure_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def getClassifier(args,runs_dir=None):\n",
    "    \n",
    "    (method,optim,lr,reg,batch_size,input_dim,num_class,num_epochs) = args\n",
    "    if runs_dir is not None:\n",
    "        ensure_dir(runs_dir)\n",
    "    \n",
    "    clf = Classifier(method,input_dim,num_class,lr=lr,reg=reg,num_epochs=num_epochs,\n",
    "                        batch_size=batch_size,runs_dir=runs_dir)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "#hyperparameters\n",
    "batch_size = 4096*5 # increasing batch size with more gpu added\n",
    "optim = 'Adam'\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rates = [1e-3]\n",
    "regularizations = [1e-3]\n",
    "\n",
    "\n",
    "accuracies = {}\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "architecture = '1DCNNconv_2_fc_1'\n",
    "run_number = 4\n",
    "method='cnn2'\n",
    "\n",
    "# Cross-validation\n",
    "K=5\n",
    "skf = StratifiedKFold(n_splits=K,random_state=SEED, shuffle=True)\n",
    "for fold_index, (train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "        print('---------------------------------------------')\n",
    "        print('Fold #{}'.format(fold_index))    \n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        input_dim = X_train.shape[1]\n",
    "        num_class = len(np.unique(y_train))\n",
    "        \n",
    "        for lr in learning_rates:\n",
    "            for reg in regularizations:\n",
    "\n",
    "                classifier_args = (method,optim,lr,reg,batch_size,input_dim,num_class,num_epochs)\n",
    "                config =  '{}/{}th_run/optim_{}_lr_{}_reg_{}_bs_{}'.format(architecture,run_number,optim,lr,reg,batch_size)\n",
    "                runs_dir = join(dataroot,'runs',config)\n",
    "\n",
    "                X_train = X_train.astype(float)\n",
    "                y_train = y_train.astype(int)\n",
    "                p = np.random.permutation(len(y_train))\n",
    "                X_train = X_train[p]\n",
    "                y_train = y_train[p]\n",
    "                X_train,y_train = balance_data(X_train,y_train,seed=SEED)\n",
    "\n",
    "                tick = time.time()\n",
    "                clf = getClassifier(classifier_args,runs_dir)\n",
    "\n",
    "                clf.fit(X_train,y_train)\n",
    "                pred = clf.predict(X_test,eval_mode=True)\n",
    "\n",
    "                acc = metrics.balanced_accuracy_score(y_test,pred)*100\n",
    "                if acc >best_acc:\n",
    "                    best_model = clf\n",
    "                    best_acc = acc\n",
    "                accuracies[(lr,reg)]=acc\n",
    "                tock = time.time() # Calculating the time it takes to train the algorithm\n",
    "                \n",
    "                print(\"Model is trained in {} sec\".format(tock-tick))\n",
    "                \n",
    "                #Cross validation results\n",
    "                print(\"Balanced test accuracy: \", acc)\n",
    "                \n",
    "            # Labels\n",
    "            target_names = ['Benign', 'Botnet', 'DDoS', 'DoS GoldenEye', 'DoS Hulk',\n",
    "                            'DoS Slowhttptest', 'DoS slowloris', 'FTP-Patator', 'Heartbleed', \n",
    "                            'Infiltration', 'PortScan', 'SSH-Patator', 'Web Attack - Brute Force',\n",
    "                            'Web Attack - Sql Injection', 'Web Attack - XSS']\n",
    "\n",
    "            # Confusion metrics\n",
    "            print(classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "            # Confusion metrics heat map\n",
    "            conf_matrix = confusion_matrix(y_test, pred)\n",
    "            cm_df = pd.DataFrame(conf_matrix)\n",
    "            plt.figure(figsize=(20,15))\n",
    "            sns.set(font_scale=1.4)\n",
    "            sns.heatmap(cm_df, annot=True, annot_kws={\"size\":12}, fmt='g', xticklabels=target_names,\n",
    "                        yticklabels=target_names)\n",
    "            plt.ylabel('Actual Class')\n",
    "            plt.xlabel('Predicted Class')\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            # Metrics that might be needed\n",
    "            # FP: False Positive\n",
    "            # FN: False Negative\n",
    "            # TP: True Positive\n",
    "            # TN: True Negative\n",
    "            FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
    "            FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "            TP = np.diag(conf_matrix)\n",
    "            TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "\n",
    "            FP = FP.astype(float)\n",
    "            FN = FN.astype(float)\n",
    "            TP = TP.astype(float)\n",
    "            TN = TN.astype(float)\n",
    "\n",
    "            # True Positive Rate (TPR) / Recall / Detection Rate (DR)\n",
    "            TPR = TP/(TP+FN)\n",
    "            # True Negative Rate (TNR) / Specificity\n",
    "            TNR = TN/(TN+FP) \n",
    "            #  Positive Predictive Value (PPV) / Precision\n",
    "            PPV = TP/(TP+FP)\n",
    "            # Negative Predictive Value (NPV)\n",
    "            NPV = TN/(TN+FN)\n",
    "            # False Positive Rate (FPR)\n",
    "            FPR = FP/(FP+TN)\n",
    "            # False Negative Rate (FNR)\n",
    "            FNR = FN/(TP+FN)\n",
    "            # False Discovery Rate (FDR)\n",
    "            FDR = FP/(TP+FP)\n",
    "            # Overall accuracy. Not needed due to the imbalance of the dataset\n",
    "            ACC = (TP+TN)/(TP+FP+FN+TN)           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
